[{"authors":["admin"],"categories":null,"content":"I am a first year PhD Student in the Computer Science Department at Johns Hopkins University. I am fortunate to be advised by Professor Jeremias Sulam. My research interests revolve around theoretical questions in machine learning and robustness gaurantees. I am also interested in exploiting structure in data to develop efficient algorithms (eg. sparsity, low rank).\nPrior to starting my graduate studies, I was a research assistant at ORIE Department at Cornell where I was supervised by Professor Madeleine Udell. My work at Cornell involved developing low-memory algorithms for PDE-optimization (in collaboration with Dr. Drew Kouri of Sandia National Laboratories).\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ramcha24.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a first year PhD Student in the Computer Science Department at Johns Hopkins University. I am fortunate to be advised by Professor Jeremias Sulam. My research interests revolve around theoretical questions in machine learning and robustness gaurantees. I am also interested in exploiting structure in data to develop efficient algorithms (eg. sparsity, low rank).\nPrior to starting my graduate studies, I was a research assistant at ORIE Department at Cornell where I was supervised by Professor Madeleine Udell.","tags":null,"title":"Ramchandran Muthukumar","type":"authors"},{"authors":[],"categories":[],"content":" Trial post to see if I can blog my notes\nMathematical Setup Standard Classification Error Let $\\mathcal{P} : \\mathbb{R}^d\\times {-1,+1} \\rightarrow \\mathbb{R}$ be the data distribution over input data and output label, $(x,y)$. Let $f:\\mathbb{R}^d \\rightarrow {-1,+1}$ be a classifier that maps input data to output label.\nThe standard classification error, $\\beta(f)$ is defined to be, $$ \\beta(f) = \\mathrm{Pr}_{(x,y) \\sim \\mathcal{P}} \\left[f(x) \\neq y \\right] $$ Here, $\\beta(f)$ is the probability that an input data and output label sampled from $\\mathcal{P}$ is misclassified by the classifier $f$.\nRobust Classification Error Let $\\mathcal{P} : \\mathbb{R}^d\\times {-1,+1} \\rightarrow \\mathbb{R}$ be the data distribution over input data and output label, $(x,y)$. Let $f:\\mathbb{R}^d \\rightarrow {-1,+1}$ be a classifier that maps input data to output label. Let $\\mathcal{B}:\\mathbb{R}^d \\times \\mathfrak{P}(\\mathbb{R}^d)$ be the perturbation set that maps input data to a set of points near it.\nThe $\\mathcal{B}$-robust classification error, $\\beta(f)$ is defined to be, $$ \\beta(f) = \\mathrm{Pr}_{(x,y) \\sim \\mathcal{P}} \\left[\\exists \\; x\u0026rsquo; \\in \\mathcal{B}(x) \\text{ such that } f(x\u0026rsquo;) \\neq y \\right] $$\nHere, $\\beta(f)$ is the probability that an input data and output label $(x,y)$ sampled from $\\mathcal{P}$ is misclassified by the classifier $f$ on any point $x\u0026rsquo;$ near $x$.\nQuestion 1 : If we sample a pair $(x,y) \\sim P$ where $y \\;|\\; x$ is very unlikely, wouldn\u0026rsquo;t this automatically result in a high probability that there exists a $x\u0026rsquo; \\in \\mathcal{B}(x)$ such that $f(x\u0026rsquo;) \\neq y$. The current definition of robust error includes the probability of these events. Shouldn\u0026rsquo;t we be looking at a different definition of robust classification error? One that will not take such a misclassification into account? Perhaps we should weight the probability stronger to bias it towards not penalizing for misclassifying edge cases\nQuestion 2 : In the gaussian model for data, for all $x$ there is a non-zero probability that the label is $y_1$ or $y_2$. so, no matter what $x,y$ we sample and what our classifier $f$ is, there exists $x\u0026rsquo;$ such that $f(x\u0026rsquo;)\\neq y$ What exactly is the probabilty being calculated? Is it,\n$$ \\mathrm{Pr}_{(x,y) \\sim \\mathcal{P}, \\; (x\u0026rsquo;,y) \\sim P, \\; x\u0026rsquo; \\in \\mathcal{B}(x)} \\left[f(x\u0026rsquo;) \\neq y \\right] \\quad ? $$\nWe specifically define the set of perturbations w.r.t to the norm $l_{\\infty}$ as, $$\\mathcal{B}^{\\epsilon}_{\\infty} (x) := \\{ x\u0026rsquo; \\in \\mathbb{R}^d \\text{ such that } |x\u0026rsquo;-x|_{\\infty} \\leq \\epsilon \\}$$\nWe refer to $\\mathcal{B}^{\\epsilon}_{\\infty}$ robustness as simply $l_{\\infty}$-robustness.\nAn example classifier For a parameter vector $w$, the linear classifier $f_w : \\mathbb{R}\\times{-1,+1}$ is defined as $$f_w(x):= \\text{sign}(\\langle w,x\\rangle)$$\nThe Gaussian Model for data distribution The model of data $(x,y)$ is two spherical Gaussians with one component per output class. Let $\\theta^{\\star} \\in \\mathbb{R}^d$ be the per-class mean vector. Let $\\sigma \u0026gt; 0$ be the variance parameter for each each Gaussian.\nWe define the following distributions over data $(x,y) \\in \\mathbb{R}^d \\times {-1,+1}$ to be the $(\\theta^{\\star},\\sigma)-$ Gaussian Model : - First, draw a random label $y \\in {-1,+1}$ uniformly at random. - Sample the data point $x\\in \\mathbb{R}^d$ according to $\\mathcal{N}(y \\cdot \\theta^{\\star},\\sigma^2I)$\ni.e. the points that are labelled positive have the distribution $\\mathcal{N}(\\theta^{\\star},\\sigma^2I)$. and, the points that are labelled negative have the distribution $\\mathcal{N}(-\\theta^{\\star},\\sigma^2I)$.\nWe want a classifier that separates these two points and has low generalization error (standard and robust)\nWe assume here that $|\\theta^{\\star}|_2 \\approx \\sqrt{d}$. Therfore, if the variance $\\sigma^2$ is too high then there is more overlap between the two gaussians.\nTheorem 4: Standard generalizaiton of a Linear classifier under the Guassian Model (with single sample) Let $(x,y)$ be drawn from a $(\\theta^{\\star},\\sigma)-$Gaussian model where for some constant $c$, $$|\\theta^{\\star}|_2 = \\sqrt{d}, \\quad \\sigma \\leq c\\cdot d^{\\frac{1}{4}}$$\nChoose parameter vector $\\hat{w} := y\\cdot x$ for the classifier.\nThen with high probability, the linear classifier $f_{\\hat{w}}$ has classification error $\\leq 1\\%$.\nTheorem 5: Robust error of Linear classifier under the Gaussian Model (under n samples) Lets draw $n$ samples i.i.d from the $(\\theta^{\\star},\\sigma)-$Gaussian model : $(x_1,y_1),\\ldots,(x_n,y_n)$. Again the parameters of the guassian model are such that for some constant $c_1$, $$|\\theta^{\\star}|_2 = \\sqrt{d}, \\quad \\sigma \\leq c_1\\cdot d^{\\frac{1}{4}}$$\nChoose for the classifier, the parameter vector $\\hat{w} := \\frac{1}{n}\\sum_{i=1}^n y_ix_i$ which is the class-weighted sample mean.\nThen with high probability the linear classifier $f_{\\hat{w}}$ has $l^{\\epsilon}_{\\infty}$-robust classification error $\\leq 1\\%$ , if,\n$$ n \\geq \\begin{cases} 1 \u0026amp;\\quad \\text{ for } \\epsilon \\leq \\frac{1}{4}d^{\\frac{-1}{4}}, \\\\ c_2 \\epsilon^2 \\sqrt{d} \u0026amp;\\quad \\text{ for } \\frac{1}{4}d^{\\frac{-1}{4}} \\leq \\epsilon \\leq \\frac{1}{4}. \\end{cases} $$\nTherefore if the $\\epsilon$ is small enough it is possible to learn a $l^{\\epsilon}_{\\infty}$-robust classification error given large enough number of samples $n$.\nTheorem 6: Robust error of ANY classifier under the Gaussian Model (under n samples) Lets draw $n$ samples i.i.d from the $(\\theta,\\sigma)-$Gaussian model : $(x_1,y_1),\\ldots,(x_n,y_n)$. Again the parameters of the guassian model are such that for some constant $c_1$, $$\\theta \\sim \\mathcal{N}(0,I), \\quad \\sigma = c_1\\cdot d^{\\frac{1}{4}}$$\nLet $g_n$ be ANY learning algorithm that gives a binary classifier $f_n$.\nThen, the expected $l^{\\epsilon}_{\\infty}$-robust classification error of $f_n$ is at least $(1-\\frac{1}{d})\\frac{1}{2}$ , if $$n \\leq c_2 \\frac{\\epsilon^2 \\sqrt{d}}{\\log(d)}.\n$$\nTherefore if the sample size is smaller than the quantity given, then the expected robust classification accuracy of ANY classifier is lower bounded by $(1-\\frac{1}{d})\\frac{1}{2}$.\nTo do better than that we necessarily need more samples (that is larger $n$).\nNote : A classifier that predicts either class every time will have robust error of $\\frac{1}{2}$. Thus this lower bound is tight in that it says for a small enough $n$, ANY classifier is going to have (in expectation) error in the interval ${\\frac{1}{2}-\\frac{1}{2d},1}$, while trivial classifier already achieves expected error of $\\frac{1}{2}$. This lower -bound becomes worse when we are dealing with data of larger dimensions!. This statement also holds for ANY $\\epsilon \u0026gt;0$.\nBernoulli Model The model of the data $(x,y)$ is defined on the hypercube $\\{-1,+1\\}^d$ with the two classes being opposite vertices.\nLet $\\theta^* \\in \\{-1,+1\\}^d$ be the per-class mean vector. Let $\\tau \u0026gt; 0$ be the class bias parameter.\nWe define the following distributions over data $(x,y) \\in \\{-1,+1\\}^d \\times \\{-1,+1\\}$ to be the $(\\theta^{\\star},\\tau)-$ Bernoulli Model : - First, draw a label $y \\in \\{-1,+1\\}$ uniformly at random. - Sample the data point $x\\in \\{-1,+1\\}^d$ by sampling each co-ordinate $x_i$ from the distribution,\n$$x_i = \\begin{cases} y\\cdot \\theta_i^* \u0026amp;, \\quad \\text{with probability } \\frac{1}{2}+\\tau \\\\ -y\\cdot \\theta_i^* \u0026amp;, \\quad \\text{with probability } \\frac{1}{2}-\\tau \\end{cases} $$\nNote that, $\\mathbb{E}[x_i] = 2\\tau \\cdot y\\cdot \\theta^*_i $.\nThe points that are labelled positive have the bernoulli distribution with expected value $2\\tau \\cdot \\theta^*$.\nThe points that are labelled negative have the bernoulli distribution with expected value $-2\\tau \\cdot \\theta^*$.\nWe want a classifier that separates these two points and has low generalization error (standard and robust)\nAs before, $\\tau$, the bias dictates the amount of overlap between the two classes. If $\\tau = \\frac{1}{2}$, then zero overlap. If $\\tau = 0$, then maximum overlap (no bias).\nTheorem 8: Standard generalizaiton of a Linear classifier under the Bernoulli Model (with single sample) Let $(x,y)$ be drawn from a $(\\theta^{\\star},\\tau)$-Bernoulli model where for some constant $c$ such that , $$\\tau \\geq c\\cdot d^{-\\frac{1}{4}}$$\nChoose parameter vector $\\hat{w} := y\\cdot x$ for the classifier.\nThen with high probability, the linear classifier $f_{\\hat{w}}$ has classification error $\\leq 1\\%$.\nTheorem 9: Robust error of ANY linear classifier under the Bernoulli Model (under n samples) Lets draw $n$ samples i.i.d from the $(\\theta,\\sigma)-$Gaussian model : $(x_1,y_1),\\ldots,(x_n,y_n)$. Again the parameters of the bernoulli model are such that for some constant $c_1$, $$\\theta^* \\sim \\text{Uniform}{-1,+1}^d, \\quad \\tau = c_1\\cdot d^{-\\frac{1}{4}}$$\nLet $g_n$ be ANY learning algorithm that gives a linear binary classifier $f_n$.\nLet $\\epsilon \u0026lt; 3 \\tau$ and $0 \\leq \\gamma \\leq \\frac{1}{2}$.\nThen, the expected $l^{\\epsilon}_{\\infty}$-robust classification error of $f_n$ is at least $\\frac{1}{2}-\\gamma$ , if $$ n \\leq c_2 \\frac{\\epsilon^2 \\gamma^2d}{\\log(\\frac{d}{\\gamma})}.\n$$\nTherefore if the sample size is smaller than the quantity given, then the expected robust classification accuracy of ANY classifier is lower bounded by $(1-\\frac{1}{d})\\frac{1}{2}$.\nTo do better than that we necessarily need more samples (that is larger $n$).\nNote : A classifier that predicts either class every time will have robust error of $\\frac{1}{2}$. Thus this lower bound is tight in that it says for a small enough $n$, ANY classifier is going to have (in expectation) error in the interval ${\\frac{1}{2}-\\frac{1}{2d},1}$, while trivial classifier already achieves expected error of $\\frac{1}{2}$. This lower -bound becomes worse when we are dealing with data of larger dimensions!. This statement also holds for ANY $\\epsilon \u0026gt;0$.\n","date":1572545862,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572545862,"objectID":"be3d5cf9cd6acbc273a36563933ffdd6","permalink":"https://ramcha24.github.io/post/my-first-post/","publishdate":"2019-10-31T14:17:42-04:00","relpermalink":"/post/my-first-post/","section":"post","summary":"Trial post to see if I can blog my notes\nMathematical Setup Standard Classification Error Let $\\mathcal{P} : \\mathbb{R}^d\\times {-1,+1} \\rightarrow \\mathbb{R}$ be the data distribution over input data and output label, $(x,y)$. Let $f:\\mathbb{R}^d \\rightarrow {-1,+1}$ be a classifier that maps input data to output label.\nThe standard classification error, $\\beta(f)$ is defined to be, $$ \\beta(f) = \\mathrm{Pr}_{(x,y) \\sim \\mathcal{P}} \\left[f(x) \\neq y \\right] $$ Here, $\\beta(f)$ is the probability that an input data and output label sampled from $\\mathcal{P}$ is misclassified by the classifier $f$.","tags":[],"title":"Adversarial Robust Generalization requires more data (Schmidt et. al)","type":"post"}]