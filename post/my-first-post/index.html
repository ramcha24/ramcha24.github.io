<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.5.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Ramchandran Muthukumar">

  
  
  
    
  
  <meta name="description" content="Trial post to see if I can blog my notes
Mathematical Setup Standard Classification Error Let $\mathcal{P} : \mathbb{R}^d\times {-1,&#43;1} \rightarrow \mathbb{R}$ be the data distribution over input data and output label, $(x,y)$. Let $f:\mathbb{R}^d \rightarrow {-1,&#43;1}$ be a classifier that maps input data to output label.
The standard classification error, $\beta(f)$ is defined to be, $$ \beta(f) = \mathrm{Pr}_{(x,y) \sim \mathcal{P}} \left[f(x) \neq y \right] $$ Here, $\beta(f)$ is the probability that an input data and output label sampled from $\mathcal{P}$ is misclassified by the classifier $f$.">

  
  <link rel="alternate" hreflang="en-us" href="https://ramcha24.github.io/post/my-first-post/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.891726ba3b332d3508fbc99721fa7e80.css">

  

  
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://ramcha24.github.io/post/my-first-post/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ramcha1994">
  <meta property="twitter:creator" content="@ramcha1994">
  
  <meta property="og:site_name" content="Ramchandran Muthukumar">
  <meta property="og:url" content="https://ramcha24.github.io/post/my-first-post/">
  <meta property="og:title" content="Adversarial Robust Generalization requires more data (Schmidt et. al) | Ramchandran Muthukumar">
  <meta property="og:description" content="Trial post to see if I can blog my notes
Mathematical Setup Standard Classification Error Let $\mathcal{P} : \mathbb{R}^d\times {-1,&#43;1} \rightarrow \mathbb{R}$ be the data distribution over input data and output label, $(x,y)$. Let $f:\mathbb{R}^d \rightarrow {-1,&#43;1}$ be a classifier that maps input data to output label.
The standard classification error, $\beta(f)$ is defined to be, $$ \beta(f) = \mathrm{Pr}_{(x,y) \sim \mathcal{P}} \left[f(x) \neq y \right] $$ Here, $\beta(f)$ is the probability that an input data and output label sampled from $\mathcal{P}$ is misclassified by the classifier $f$."><meta property="og:image" content="https://ramcha24.github.io/img/static/img/profile.jpeg">
  <meta property="twitter:image" content="https://ramcha24.github.io/img/static/img/profile.jpeg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-10-31T14:17:42-04:00">
    
    <meta property="article:modified_time" content="2019-10-31T14:17:42-04:00">
  

  


    






  





  





  





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ramcha24.github.io/post/my-first-post/"
  },
  "headline": "Adversarial Robust Generalization requires more data (Schmidt et. al)",
  
  "datePublished": "2019-10-31T14:17:42-04:00",
  "dateModified": "2019-10-31T14:17:42-04:00",
  
  "author": {
    "@type": "Person",
    "name": "Ramchandran Muthukumar"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Ramchandran Muthukumar",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ramcha24.github.io/img/icon-512.png"
    }
  },
  "description": "Trial post to see if I can blog my notes\nMathematical Setup Standard Classification Error Let $\\mathcal{P} : \\mathbb{R}^d\\times {-1,+1} \\rightarrow \\mathbb{R}$ be the data distribution over input data and output label, $(x,y)$. Let $f:\\mathbb{R}^d \\rightarrow {-1,+1}$ be a classifier that maps input data to output label.\nThe standard classification error, $\\beta(f)$ is defined to be, $$ \\beta(f) = \\mathrm{Pr}_{(x,y) \\sim \\mathcal{P}} \\left[f(x) \\neq y \\right] $$ Here, $\\beta(f)$ is the probability that an input data and output label sampled from $\\mathcal{P}$ is misclassified by the classifier $f$."
}
</script>

  

  


  


  





  <title>Adversarial Robust Generalization requires more data (Schmidt et. al) | Ramchandran Muthukumar</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Ramchandran Muthukumar</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Adversarial Robust Generalization requires more data (Schmidt et. al)</h1>

  

  
    



<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Oct 31, 2019
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="/post/my-first-post/#disqus_thread"></a>
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://ramcha24.github.io/post/my-first-post/&amp;text=Adversarial%20Robust%20Generalization%20requires%20more%20data%20%28Schmidt%20et.%20al%29" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://ramcha24.github.io/post/my-first-post/&amp;t=Adversarial%20Robust%20Generalization%20requires%20more%20data%20%28Schmidt%20et.%20al%29" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Adversarial%20Robust%20Generalization%20requires%20more%20data%20%28Schmidt%20et.%20al%29&amp;body=https://ramcha24.github.io/post/my-first-post/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://ramcha24.github.io/post/my-first-post/&amp;title=Adversarial%20Robust%20Generalization%20requires%20more%20data%20%28Schmidt%20et.%20al%29" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Adversarial%20Robust%20Generalization%20requires%20more%20data%20%28Schmidt%20et.%20al%29%20https://ramcha24.github.io/post/my-first-post/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://ramcha24.github.io/post/my-first-post/&amp;title=Adversarial%20Robust%20Generalization%20requires%20more%20data%20%28Schmidt%20et.%20al%29" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      

<p>Trial post to see if I can blog my notes</p>

<h2 id="mathematical-setup">Mathematical Setup</h2>

<h3 id="standard-classification-error">Standard Classification Error</h3>

<p>Let $\mathcal{P} : \mathbb{R}^d\times {-1,+1} \rightarrow \mathbb{R}$ be the <strong>data distribution</strong> over input data and output label,  $(x,y)$.
Let $f:\mathbb{R}^d  \rightarrow {-1,+1}$ be a <strong>classifier</strong> that maps input data to output label.</p>

<p>The <strong>standard classification error</strong>, $\beta(f)$ is defined to be,
$$
\beta(f) = \mathrm{Pr}_{(x,y) \sim \mathcal{P}} \left[f(x) \neq y \right]
$$
Here, $\beta(f)$ is the probability that an input data and output label sampled from $\mathcal{P}$ is misclassified by the classifier $f$.</p>

<h3 id="robust-classification-error">Robust Classification Error</h3>

<p>Let $\mathcal{P} : \mathbb{R}^d\times {-1,+1} \rightarrow \mathbb{R}$ be the <strong>data distribution</strong> over input data and output label,  $(x,y)$.
Let $f:\mathbb{R}^d  \rightarrow {-1,+1}$ be a <strong>classifier</strong> that maps input data to output label.
Let $\mathcal{B}:\mathbb{R}^d \times \mathfrak{P}(\mathbb{R}^d)$ be the <strong>perturbation set</strong> that maps input data to a set of points <em>near</em> it.</p>

<p>The <strong>$\mathcal{B}$-robust classification error</strong>, $\beta(f)$ is defined to be,
$$
\beta(f) = \mathrm{Pr}_{(x,y) \sim \mathcal{P}} \left[\exists \; x&rsquo; \in \mathcal{B}(x) \text{ such that } f(x&rsquo;) \neq y \right]
$$</p>

<p>Here, $\beta(f)$ is the probability that an input data and output label $(x,y)$ sampled from $\mathcal{P}$ is misclassified by the classifier $f$ on any point $x&rsquo;$ near $x$.</p>

<p><strong>Question 1</strong> :
If we sample a pair $(x,y) \sim P$ where $y \;|\; x$ is very unlikely, wouldn&rsquo;t this automatically result in a high probability that there exists a $x&rsquo; \in \mathcal{B}(x)$ such that $f(x&rsquo;) \neq y$.
The current definition of robust error includes the probability of these events.
Shouldn&rsquo;t we be looking at a different definition of robust classification error? One that will not take such a misclassification into account?
Perhaps we should weight the probability stronger to bias it towards not penalizing for misclassifying edge cases</p>

<p><strong>Question 2</strong> :
In the gaussian model for data, for all $x$ there is a non-zero probability that the label is $y_1$ or $y_2$.
so, no matter what $x,y$ we sample and what our classifier $f$ is, there exists $x&rsquo;$ such that $f(x&rsquo;)\neq y$
What exactly is the probabilty being calculated?
Is it,</p>

<p>$$
\mathrm{Pr}_{(x,y) \sim \mathcal{P}, \; (x&rsquo;,y) \sim P, \; x&rsquo; \in \mathcal{B}(x)} \left[f(x&rsquo;) \neq y \right]  \quad ?
$$</p>

<p>We specifically define the set of perturbations w.r.t to the norm $l_{\infty}$ as,
$$\mathcal{B}^{\epsilon}_{\infty} (x) := \{ x&rsquo; \in \mathbb{R}^d \text{ such that } |x&rsquo;-x|_{\infty} \leq \epsilon \}$$</p>

<p>We refer to $\mathcal{B}^{\epsilon}_{\infty}$ robustness as simply $l_{\infty}$-robustness.</p>

<h3 id="an-example-classifier">An example classifier</h3>

<p>For a parameter vector $w$, the <strong>linear classifier</strong> $f_w : \mathbb{R}\times{-1,+1}$ is defined as
$$f_w(x):= \text{sign}(\langle w,x\rangle)$$</p>

<h3 id="the-gaussian-model-for-data-distribution">The Gaussian Model for data distribution</h3>

<p>The model of data $(x,y)$ is two spherical Gaussians with one component per output class.
Let $\theta^{\star} \in \mathbb{R}^d$ be the per-class mean vector.
Let $\sigma &gt; 0$ be the variance parameter for each each Gaussian.</p>

<p>We define the following distributions over data $(x,y) \in \mathbb{R}^d \times {-1,+1}$ to be the $(\theta^{\star},\sigma)-$ Gaussian Model :
- First, draw a random label $y \in {-1,+1}$ uniformly at random.
- Sample the data point $x\in \mathbb{R}^d$ according to $\mathcal{N}(y \cdot \theta^{\star},\sigma^2I)$</p>

<p>i.e. the points that are labelled positive have the distribution $\mathcal{N}(\theta^{\star},\sigma^2I)$.
and, the points that are labelled negative have the distribution $\mathcal{N}(-\theta^{\star},\sigma^2I)$.</p>

<p>We want a classifier that separates these two points and has low generalization error (standard and robust)</p>

<p>We assume here that $|\theta^{\star}|_2 \approx \sqrt{d}$. Therfore, if the variance $\sigma^2$ is  too high then there is more overlap between the two gaussians.</p>

<h3 id="theorem-4">Theorem 4:</h3>

<p><strong>Standard generalizaiton of a Linear classifier under the Guassian Model (with single sample)</strong>
Let $(x,y)$ be drawn from a $(\theta^{\star},\sigma)-$Gaussian model where for some constant $c$,
$$|\theta^{\star}|_2 = \sqrt{d}, \quad \sigma \leq c\cdot d^{\frac{1}{4}}$$</p>

<p>Choose parameter vector $\hat{w} := y\cdot x$ for the classifier.</p>

<p>Then with high probability, the linear classifier $f_{\hat{w}}$ has classification error $\leq 1\%$.</p>

<h3 id="theorem-5">Theorem 5:</h3>

<p><strong>Robust error of Linear classifier under the Gaussian Model (under n samples)</strong>
Lets draw $n$ samples i.i.d from the $(\theta^{\star},\sigma)-$Gaussian model : $(x_1,y_1),\ldots,(x_n,y_n)$.
Again the parameters of the guassian model are such that for some constant $c_1$,
$$|\theta^{\star}|_2 = \sqrt{d}, \quad \sigma \leq c_1\cdot d^{\frac{1}{4}}$$</p>

<p>Choose for the classifier, the parameter vector $\hat{w} := \frac{1}{n}\sum_{i=1}^n y_ix_i$ which is the class-weighted sample mean.</p>

<p>Then with high probability the linear classifier $f_{\hat{w}}$ has $l^{\epsilon}_{\infty}$-robust classification error $\leq 1\%$ , <strong>if</strong>,<br />
$$
n \geq
\begin{cases}
1 &amp;\quad \text{ for } \epsilon \leq \frac{1}{4}d^{\frac{-1}{4}}, \\
c_2 \epsilon^2 \sqrt{d} &amp;\quad \text{ for } \frac{1}{4}d^{\frac{-1}{4}} \leq \epsilon \leq \frac{1}{4}.
\end{cases}
$$</p>

<p>Therefore if the $\epsilon$ is small enough it is possible to learn a $l^{\epsilon}_{\infty}$-robust classification error given large enough number of samples $n$.</p>

<h3 id="theorem-6">Theorem 6:</h3>

<p><strong>Robust error of ANY classifier under the Gaussian Model (under n samples)</strong>
Lets draw $n$ samples i.i.d from the $(\theta,\sigma)-$Gaussian model : $(x_1,y_1),\ldots,(x_n,y_n)$.
Again the parameters of the guassian model are such that for some constant $c_1$,
$$\theta \sim \mathcal{N}(0,I), \quad \sigma = c_1\cdot d^{\frac{1}{4}}$$</p>

<p>Let $g_n$ be ANY learning algorithm that gives a binary classifier $f_n$.</p>

<p>Then, the expected $l^{\epsilon}_{\infty}$-robust classification error of $f_n$ is at least $(1-\frac{1}{d})\frac{1}{2}$ , <strong>if</strong>
$$n \leq c_2 \frac{\epsilon^2 \sqrt{d}}{\log(d)}.<br />
$$</p>

<p>Therefore if the sample size is smaller than the quantity given, then the <strong>expected</strong> robust classification accuracy of <strong>ANY classifier</strong> is <strong>lower bounded</strong> by $(1-\frac{1}{d})\frac{1}{2}$.</p>

<p>To do better than that we necessarily need more samples (that is larger $n$).</p>

<p>Note : A classifier that predicts either class every time will have robust error of $\frac{1}{2}$. Thus this lower bound is tight in that it says for a small enough $n$, ANY classifier is going to have (<strong>in expectation</strong>) error in the interval ${\frac{1}{2}-\frac{1}{2d},1}$, while trivial classifier already achieves expected error of $\frac{1}{2}$.
This lower -bound becomes worse when we are dealing with data of larger dimensions!. This statement also holds for ANY $\epsilon &gt;0$.</p>

<h3 id="bernoulli-model">Bernoulli Model</h3>

<p>The model of the data $(x,y)$ is defined on the hypercube $\{-1,+1\}^d$ with the two classes being opposite vertices.</p>

<p>Let $\theta^* \in \{-1,+1\}^d$ be the per-class mean vector.
Let $\tau &gt; 0$ be the class bias parameter.</p>

<p>We define the following distributions over data $(x,y) \in \{-1,+1\}^d \times \{-1,+1\}$ to be the $(\theta^{\star},\tau)-$ Bernoulli Model :
- First, draw a label $y \in \{-1,+1\}$ uniformly at random.
- Sample the data point $x\in \{-1,+1\}^d$ by sampling each co-ordinate $x_i$ from the distribution,</p>

<p>$$x_i = \begin{cases}
y\cdot \theta_i^* &amp;, \quad \text{with probability } \frac{1}{2}+\tau \\
-y\cdot \theta_i^* &amp;, \quad \text{with probability } \frac{1}{2}-\tau
\end{cases}
$$</p>

<p>Note that, $\mathbb{E}[x_i] = 2\tau \cdot y\cdot \theta^*_i $.</p>

<p>The points that are labelled positive have the bernoulli distribution with expected value $2\tau \cdot \theta^*$.</p>

<p>The points that are labelled negative have the bernoulli distribution with expected value $-2\tau \cdot \theta^*$.</p>

<p>We want a classifier that separates these two points and has low generalization error (standard and robust)</p>

<p>As before, $\tau$, the bias dictates the amount of overlap between the two classes. If $\tau = \frac{1}{2}$, then zero overlap. If $\tau = 0$, then maximum overlap (no bias).</p>

<h3 id="theorem-8">Theorem 8:</h3>

<p><strong>Standard generalizaiton of a Linear classifier under the Bernoulli Model (with single sample)</strong>
Let $(x,y)$ be drawn from a $(\theta^{\star},\tau)$-Bernoulli model where for some constant $c$ such that ,
$$\tau \geq c\cdot d^{-\frac{1}{4}}$$</p>

<p>Choose parameter vector $\hat{w} := y\cdot x$ for the classifier.</p>

<p>Then with high probability, the linear classifier $f_{\hat{w}}$
has classification error $\leq 1\%$.</p>

<h3 id="theorem-9">Theorem 9:</h3>

<p><strong>Robust error of ANY linear classifier under the Bernoulli Model (under n samples)</strong>
Lets draw $n$ samples i.i.d from the $(\theta,\sigma)-$Gaussian model : $(x_1,y_1),\ldots,(x_n,y_n)$.
Again the parameters of the bernoulli model are such that for some constant $c_1$,
$$\theta^* \sim \text{Uniform}{-1,+1}^d, \quad \tau = c_1\cdot d^{-\frac{1}{4}}$$</p>

<p>Let $g_n$ be ANY learning algorithm that gives a linear binary classifier $f_n$.</p>

<p>Let $\epsilon &lt; 3 \tau$ and $0 \leq \gamma \leq \frac{1}{2}$.</p>

<p>Then, the expected $l^{\epsilon}_{\infty}$-robust classification error of $f_n$ is at least $\frac{1}{2}-\gamma$ , <strong>if</strong>
$$
n \leq c_2 \frac{\epsilon^2 \gamma^2d}{\log(\frac{d}{\gamma})}.<br />
$$</p>

<p>Therefore if the sample size is smaller than the quantity given, then the <strong>expected</strong> robust classification accuracy of <strong>ANY classifier</strong> is <strong>lower bounded</strong> by $(1-\frac{1}{d})\frac{1}{2}$.</p>

<p>To do better than that we necessarily need more samples (that is larger $n$).</p>

<p>Note : A classifier that predicts either class every time will have robust error of $\frac{1}{2}$. Thus this lower bound is tight in that it says for a small enough $n$, ANY classifier is going to have (<strong>in expectation</strong>) error in the interval ${\frac{1}{2}-\frac{1}{2d},1}$, while trivial classifier already achieves expected error of $\frac{1}{2}$.
This lower -bound becomes worse when we are dealing with data of larger dimensions!. This statement also holds for ANY $\epsilon &gt;0$.</p>

    </div>

    


    



    
      








  






  
  
  
    
  
  
  <div class="media author-card">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu603214eba84c3f34cdae84e425659540_24432_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://ramcha24.github.io/">Ramchandran Muthukumar</a></h5>
      <h6 class="card-subtitle">PhD Student</h6>
      <p class="card-text">My research interests include theoretical machine learning, adversarial robustness and sparse coding.</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
          <li>
            <a href="mailto:ramcha1994@gmail.com" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://twitter.com/ramcha1994" target="_blank" rel="noopener">
              <i class="fab fa-twitter"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a href="https://github.com/ramcha24" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a href="/files/mycv.pdf" >
              <i class="ai ai-cv"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
    

    

    
<section id="comments">
  
    

  
</section>



  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js" integrity="sha256-0w92bcB21IY5+rGI84MGj52jNfHNbXVeQLrZ0CGdjNY=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.130521ecfc6f534c52c158217bbff718.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
